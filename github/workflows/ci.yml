name: EV Charging LLM Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly retraining on Sundays at 02:00 UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      force_retrain:
        description: 'Force model retraining'
        required: false
        default: 'false'
        type: boolean
      skip_data_collection:
        description: 'Skip data collection step'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.9'
  MODEL_REGISTRY: 'models'
  HUGGINGFACE_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}

jobs:
  # 1. Code Quality & Testing
  quality-checks:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Type checking with mypy
      run: |
        mypy --ignore-missing-imports data_processing/ data_collection/ evaluation/ deployment/
    
    - name: Security scan with bandit
      run: |
        bandit -r . -f json -o bandit-report.json || true
    
    - name: Upload security scan results
      uses: actions/upload-artifact@v3
      with:
        name: security-scan
        path: bandit-report.json

  # 2. Unit Testing
  unit-tests:
    runs-on: ubuntu-latest
    needs: quality-checks
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run unit tests
      run: |
        python -m pytest tests/ -v --cov=. --cov-report=xml --cov-report=html
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # 3. Data Collection & Processing
  data-pipeline:
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.event.inputs.skip_data_collection != 'true'
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Cache collected data
      uses: actions/cache@v3
      with:
        path: |
          data_collection/data/
          data_processing/data/
        key: ev-data-${{ hashFiles('data_collection/collect_data.py') }}-${{ github.run_number }}
        restore-keys: |
          ev-data-${{ hashFiles('data_collection/collect_data.py') }}-
    
    - name: Collect data
      run: |
        cd data_collection
        python collect_data.py
    
    - name: Process data
      run: |
        cd data_processing
        python process_data.py
    
    - name: Generate QA dataset
      run: |
        cd data_processing
        python generate_qa_dataset.py
    
    - name: Upload processed data
      uses: actions/upload-artifact@v3
      with:
        name: processed-data
        path: |
          data_processing/data/train_lora.json
          data_processing/data/eval_lora.json
          data_processing/data/qa_dataset_summary.json

  # 4. Model Training & Evaluation
  model-training:
    runs-on: ubuntu-latest
    needs: data-pipeline
    if: github.event.inputs.force_retrain == 'true' || github.event_name == 'schedule'
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install transformers[torch] peft bitsandbytes datasets accelerate
    
    - name: Download processed data
      uses: actions/download-artifact@v3
      with:
        name: processed-data
        path: data_processing/data/
    
    - name: Train model (CPU-only for CI)
      run: |
        cd data_processing
        python train_llama3_lora.py --cpu-only --max-steps 10 --save-steps 5
      env:
        WANDB_DISABLED: true
    
    - name: Evaluate model
      run: |
        cd evaluation
        python evaluate_model.py
    
    - name: Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: trained-model
        path: |
          models/
          evaluation_results/
    
    - name: Model versioning
      run: |
        echo "MODEL_VERSION=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_ENV
        mkdir -p model_registry/$MODEL_VERSION
        cp -r models/* model_registry/$MODEL_VERSION/
        echo "Trained model version: $MODEL_VERSION" > model_registry/latest.txt

  # 5. Model Validation & Quality Gates
  model-validation:
    runs-on: ubuntu-latest
    needs: model-training
    steps:
    - uses: actions/checkout@v4
    
    - name: Download model artifacts
      uses: actions/download-artifact@v3
      with:
        name: trained-model
        path: ./
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Validate model performance
      run: |
        python -c "
        import json
        with open('evaluation_results/evaluation_results.json', 'r') as f:
            results = json.load(f)
        
        # Quality gates
        min_bleu = 0.2
        min_rouge1 = 0.3
        max_latency = 1000  # ms
        
        assert results.get('bleu', 0) >= min_bleu, f'BLEU score {results.get(\"bleu\")} below threshold {min_bleu}'
        assert results.get('rouge1', 0) >= min_rouge1, f'ROUGE-1 score {results.get(\"rouge1\")} below threshold {min_rouge1}'
        assert results.get('avg_latency_ms', 9999) <= max_latency, f'Latency {results.get(\"avg_latency_ms\")}ms above threshold {max_latency}ms'
        
        print('âœ… All quality gates passed!')
        "
    
    - name: Generate model card
      run: |
        python scripts/generate_model_card.py --model-path models/ --eval-results evaluation_results/

  # 6. Security & Compliance Checks
  security-compliance:
    runs-on: ubuntu-latest
    needs: model-validation
    steps:
    - uses: actions/checkout@v4
    
    - name: Download model artifacts
      uses: actions/download-artifact@v3
      with:
        name: trained-model
        path: ./
    
    - name: Scan for sensitive data
      run: |
        # Check for potential PII or sensitive information in training data
        python scripts/scan_sensitive_data.py
    
    - name: Model bias evaluation
      run: |
        python scripts/evaluate_bias.py --model-path models/
    
    - name: License compliance check
      run: |
        pip-licenses --format=json --output-file licenses.json
        python scripts/check_license_compliance.py

  # 7. Build & Deploy
  build-deploy:
    runs-on: ubuntu-latest
    needs: [security-compliance]
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v4
    
    - name: Download model artifacts
      uses: actions/download-artifact@v3
      with:
        name: trained-model
        path: ./
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./deployment/Dockerfile
        push: true
        tags: |
          evcharging/llm-api:latest
          evcharging/llm-api:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add deployment commands here
    
    - name: Run integration tests
      run: |
        python tests/integration_tests.py --endpoint http://staging-api.example.com
    
    - name: Deploy to production
      if: success()
      run: |
        echo "Deploying to production environment..."
        # Add production deployment commands here

  # 8. Monitoring & Alerting Setup
  monitoring-setup:
    runs-on: ubuntu-latest
    needs: build-deploy
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup monitoring dashboards
      run: |
        python scripts/setup_monitoring.py
    
    - name: Configure alerts
      run: |
        python scripts/configure_alerts.py
    
    - name: Health check
      run: |
        python scripts/health_check.py --endpoint http://api.example.com/health

  # 9. Cleanup
  cleanup:
    runs-on: ubuntu-latest
    needs: [monitoring-setup]
    if: always()
    steps:
    - name: Cleanup old artifacts
      run: |
        echo "Cleaning up old model versions and artifacts..."
        # Add cleanup logic here
    
    - name: Notify completion
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#mlops'
        text: 'EV Charging LLM Pipeline deployment completed!'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
      if: always() 